# Spam Email Analysis & Reply Generation Project

## Project Overview
This project analyzes emails for spam detection and generates intelligent replies using fine-tuned LLMs. It includes both backend AI models and a user-friendly Streamlit WebUI.

## Project Structure

### Backend Components
- **preprocessing.py**: Preprocesses the DailyDialog dataset into email-style prompt-response pairs
- **train.py**: Fine-tunes GPT-2/DistilGPT-2 with LoRA for email reply generation
- **bert_classifier_tune.ipynb**: Notebook for fine-tuning BERT for spam classification

### Frontend
- **app.py**: Streamlit WebUI for email analysis and reply generation (v0.2)

### Data & Models
- **data/**: Contains datasets for training.
- **spam_classifier_model/**: Directory where the fine-tuned BERT model should be placed (required for real spam detection in the app).

### How to call the generation model:
As i have used the Lora, so the gpt2 model can not be directly called, it should be merged with the Lora.

How to understand the folder: 
âœ…Folder 1: Contains `adapter_model.safetensors` and `adapter_config.json`
a standard LoRA adapter directory. It only stores the LoRA weights and configurationâ€”not the base GPT-2 model.

`adapter_model.safetensors`: LoRA fine-tuned weights.
`adapter_config.json:` LoRA hyperparameters (e.g., rank, alpha).
Tokenizer files (`tokenizer.json`, `vocab.json`, `merges.txt`, etc.).

âœ… Folder 2: Contains `model.safetensors` and a subfolder `lora_adapter/`
The files inside should be the main body of our trained model.

`model.safetensors`: Likely the base GPT-2 model weights.
`lora_adapter/`: Contains the LoRA adapter files.
Other config and tokenizer files.

#### Way to call it
I directly share `LoRA Adapter` + `Base Model`, this way is more flexible. (Such as the folder "gpt2(300)")

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

# Load base model
base_model_name = "gpt2"  # Or you can load the model, tokenizer from Folder 2.
tokenizer = AutoTokenizer.from_pretrained(base_model_name)
model = AutoModelForCausalLM.from_pretrained(base_model_name)

# Load LoRA adapter  (the key difference from directly call a model)
lora_path = "./lora_adapter"  # Path to Folder 1
merged_model = PeftModel.from_pretrained(model, lora_path)

# Generate text
input_text = "Hello, how are you?"
inputs = tokenizer(input_text, return_tensors="pt")
outputs = merged_model.generate(**inputs, max_new_tokens=50)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

## Setup & Usage

### 1. Data Preprocessing
```bash
python preprocessing.py \
  --dataset_name kmyoo/dailydialog-tiny \
  --output_dir ./data/email_reply_dataset \
  --style support
```
This saves the processed dataset to `data/email_reply_dataset`.

### 2. Model Training
```bash
# Full parameter fine-tuning
python train.py --model_name gpt2

# With LoRA (recommended)
python train.py --model_name gpt2 --use_lora
```

The current code ignores evaluation to ensure it runs locally. Results are saved to `./results/`.

### 3. Running the WebUI
```bash
pip install -r requirements.txt
streamlit run app.py
```

## Web Application Features (v0.2)

The `app.py` provides a comprehensive interface for the project.

### Features:
- **ðŸ” Email Analysis**: 
    - Input sender, date, subject, and body.
    - Real-time spam detection using a fine-tuned BERT model.
    - Intelligent reply generation (currently using mock/generic responses, ready for LLM integration).
- **ðŸ“‹ History Tracking**: 
    - Automatically saves analysis results.
    - View past emails, classification status, and generated replies.
    - Clear history functionality.
- **âš™ï¸ Configuration**: 
    - Settings for model selection and thresholds (UI placeholders).
    - Toggle options for auto-save and confidence display.

### Current Model Implementation:
- **Spam Classifier**: 
    - **Primary**: Fine-tuned `bert-base-uncased` model.
    - **Logic**: Loads model from `spam_classifier_model/`. If not found, falls back to a mock classifier for demonstration purposes.
    - **Preprocessing**: Includes text cleaning (URL removal, special char removal) and tokenization.
- **Reply Generator**: 
    - **Current**: Mock LLM Generator producing generic professional responses.
    - **Future**: Integration with the fine-tuned GPT-2/DistilGPT-2 models from `train.py`.

### Usage Workflow:
1.  Launch the app.
2.  Enter email details in the "Analyze Email" tab.
3.  Click "Analyze Email".
4.  If the email is **Legitimate**, a reply suggestion is generated.
5.  If the email is **Spam**, it is flagged with a confidence score.
6.  Results can be copied or downloaded as text files.

## Dependencies
- streamlit >= 1.28.0
- torch >= 2.0.0
- transformers >= 4.30.0
- datasets >= 2.13.0
- peft >= 0.4.0
- evaluate >= 0.4.0
- numpy >= 1.24.0

## Notes
- Result folders generated by `train.py` have been manually deleted to keep the repository clean
- The preprocessing and training code ignores evaluation metrics to ensure local execution
- The WebUI skeleton is ready for production-ready model integration
